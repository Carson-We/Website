<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" type="text/css" href="styles/styles.css">
    <meta charset="UTF-8">
    <script src="scripts/nor.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="images/favicon.ico" rel="shortcut icon"/>
    <title>PROJECT | Carson Wu</title>
</head>
<body>
    <header>
        <h1 class="cw" onclick="goToHomePage()">Carson Wu</h1>
        <div class="dropdown">
        <button class="dropdown-btn btn dropbtn">üåç</button>
            <ul class="dropdown-content">
              <li><a href="project_zh.html">‰∏≠Êñá</a></li>
              <li><a href="project.html">Eng</a></li>
              <li><a href="project_kr.html">ÌïúÍ∏Ä</a></li>
            </ul>
          </div>
        <nav>
            <ul class="menu">
                <li><a href="about.html" target="_blank">About</a></li>
                <li><a href="Blog.html" target="_blank">Blog</a></li>
                <li><a href="contact.html" target="_blank">Contact</a></li>
                <li><a href="project.html" target="_blank">Project</a></li>
            </ul>
          </nav>
        </header>
        <section>
            <h1>My Projects</h2>
        </section>
        <section class="card-container">
            <div class="card">
                <img src="images/kristy.png" alt="Icon of A.R.I.E.L." style="width: 200px; height: 200px;">
                <h2>Advanced Retrieval and Inference Engine for Learning (A.R.I.E.L.)</h2>
                <p>A.R.I.E.L. uses natural language processing and machine learning to assist with test-related tasks, enhancing productivity and efficiency.</p>
                <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo1')">Learn More</button>
                <div id="additionalInfo1" class="additional-info">
                  <p>This system, developed using Python, is an intelligent voice assistant designed to assist with test-related tasks. Powered by natural language processing and machine learning capabilities, it can retrieve and infer knowledge from various sources to provide relevant information and support during tests. With its voice-based interface, the system aims to enhance productivity and efficiency in test preparation and execution.</p>
                  <p>Platform: Multi-platform</p>
                  <p>Language: Python</p>
                  <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Natural%20Language%20Processing/A.R.I.E.L.">GitHub</a></p>
                </div>
            </div>
            <div class="card">
                <img src="images/ana.png" alt="Icon of A.N.A." style="width: 200px; height: 200px;">
                <h2>Autonomous Neural Avatar (A.N.A.)</h2>
                <p>A.N.A. enables the creation of lifelike digital avatars with personalized appearance and behavior, revolutionizing virtual communication and self-expression.</p>
                <p><i><b>A.N.A. will be launched in the second quarter of next year.</b></i></p>
                <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo2')">Learn More</button>
                <div id="additionalInfo2" class="additional-info">
                    <p> A.N.A. (Autonomous Neural Avatar) is a state-of-the-art technology designed for creating digital replicas or avatars of oneself. This innovative system utilizes advanced algorithms and machine learning techniques to generate lifelike and interactive digital clones. With A.N.A., users can personalize their avatars, replicating their appearance, behavior, and even personality traits. This groundbreaking technology opens up possibilities for virtual communication, entertainment, and self-expression.</p>
                    <p><i><b>A.N.A. will be launched in the second quarter of next year.</b></i></p>
                    <p>Platform: /</p>
                    <p>Language: /</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/iOS-app/tree/main/A.N.A.">GitHub</a></p>
                    <p class="solid-line"></p>
                    <p> A.N.A. (Autonomous Neural Avatar) is a state-of-the-art technology designed for creating digital replicas or avatars of oneself. This innovative system utilizes advanced algorithms and machine learning techniques to generate lifelike and interactive digital clones. With A.N.A., users can personalize their avatars, replicating their appearance, behavior, and even personality traits. This groundbreaking technology opens up possibilities for virtual communication, entertainment, and self-expression.</p>
                    <p><i><b>A.N.A. will be launched in the second quarter of next year.</b></i></p>
                    <p>Platform: iOS</p>
                    <p>Language: SwiftUI</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/iOS-app/tree/main/A.N.A.">GitHub</a></p>
                </div>
            </div>
        
            <div class="card">
                <h2>Cantonese Spoken Question-Answer Dataset for Secondary School (CSQADSS)</h2>
                <p>CSQADSS is designed for training and improving Cantonese language understanding and proficiency.</p>
                <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo4')">Learn More</button>
                <div id="additionalInfo4" class="additional-info">
                    <p>CSQADSS is designed for training and improving Cantonese language understanding and proficiency.</p>
                    <p>Platform: Multi-platform</p>
                    <p>Data interchange format: JSON</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/CSQADSS">GitHub</a></p>
                </div>
            </div>
        
            <div class="card">
                <img src="images/ferd.png" alt="Icon of FERD" style="width: 200px; height: 200px;">
                <h2>FERD</h2>
                <p>FERD analyzes facial expressions using computer vision to infer emotions.</p>
                <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo5')">Learn More</button>
                <div id="additionalInfo5" class="additional-info">
                    <p>FERD is an advanced system that utilizes computer vision techniques to analyze facial details and determine human emotions. By analyzing facial expressions, FERD can infer emotions such as happiness, sadness, anger, and surprise.</p>
                    <p>Dataset:FER2013 (Facial Expression Recognition 2013 Dataset)</p>
                    <p>Platform: macOS(Create ML)</p>
                    <p>Language: /</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Computer-Vision/FERD">GitHub</a></p>
                </div>
            </div>
        </section>
    <section class="card-container">
        <div class="card">
            <img src="images/fc.png" alt="Icon of Fruit Classifier" style="width: 200px; height: 200px;">
            <h2>Fruit Classifier</h2>
            <p>Fruit Classifier use machine learning and computer vision to accurately classify fruits images.</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo6')">Learn More</button>
                <div id="additionalInfo6" class="additional-info">
                    <p>Fruit Classifier is a computer vision system that uses machine learning algorithms to classify different types of fruits. By analyzing visual features and patterns, the system can accurately identify and categorize fruits based on their appearance.</p>
                    <p>Platform: macOS(Create ML)</p>
                    <p>Language: /</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Computer-Vision/Fruit%20Classifier">GitHub</a></p>
                </div>
        </div>
        <div class="card">
            <img src="images/loka.png" alt="Icon of L.K.O.A" style="width: 200px; height: 200px;">
            <h2>Lane-Keeping and Obstacle-Avoidance System(L.K.O.A)</h2>
            <p>L.K.O.A. combines sensors, cameras, and machine learning algorithms to ensure safe and autonomous driving, improving road safety and driver assistance features.</p>
            <p><i><b>L.O.K.A. will be launched in the first quarter of next year.</b></i></p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo7')">Learn More</button>
                <div id="additionalInfo7" class="additional-info">
                    <p>L.K.O.A. is an advanced system used in automotive technology to ensure safe and autonomous driving. By combining sensors, cameras, and machine learning algorithms, L.K.O.A. enables vehicles to detect and analyze road conditions, identify lane markings, and avoid obstacles in real-time. This system plays a crucial role in enhancing road safety and improving driver assistance features.</p>
                    <p>Platform: /</p>
                    <p>Language: /</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Computer-Vision/Lane-Keeping%20and%20Obstacle-Avoidance%20System">GitHub</a></p>
                    <p><i><b>L.O.K.A. will be launched in the first quarter of next year.</b></i></p>
                </div>
        </div>
        <div class="card">
            <img src="images/mindcheck.png" alt="Icon of MindCheck" style="width: 200px; height: 200px;">
            <h2>MindCheck</h2>
            <p>MindCheck is an iOS platform built with SwiftUI for comprehensive mental health assessment and support.</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo8')">Learn More</button>
                <div id="additionalInfo8" class="additional-info">
                    <p>MindCheck is an iOS platform built with SwiftUI for comprehensive mental health assessment and support.</p>
                    <p>Platform: iOS</p>
                    <p>Language: SwiftUI</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/iOS-app/tree/main/MindCheck">GitHub</a></p>
                </div>
        </div>
        <div class="card">
            <img src="images/neuralmorse.png" alt="Icon of NeuralMorse" style="width: 200px; height: 200px;">
            <h2>NeuralMorse</h2>
            <p>NeuralMorse is a project that utilizes neural networks to translate text to Morse code and vice versa.</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo9')">Learn More</button>
                <div id="additionalInfo9" class="additional-info">
                    <p>NeuralMorse is a project that utilizes neural networks to translate text to Morse code and vice versa. This tool provides a convenient way to convert messages between human-readable text and the Morse code representation. Whether you want to communicate in Morse code or decode Morse code messages, NeuralMorse has got you covered.</p>
                    <p>Platform: Multi-platform</p>
                    <p>Language: Python</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Neural%20Network/NeuralMorse">GitHub</a></p>
                    <p class="solid-line"></p>
                    <p>NeuralMorse is a project that utilizes neural networks to translate text to Morse code and vice versa. This tool provides a convenient way to convert messages between human-readable text and the Morse code representation. Whether you want to communicate in Morse code or decode Morse code messages, NeuralMorse has got you covered.</p>
                    <p>Platform: iOS</p>
                    <p>Language: SwiftUI</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/iOS-app/tree/main/NeuralMorse">GitHub</a></p>
                </div>
        </div>
    </section>
    <section class="card-container">
        <div class="card">
            <img src="images/ic.png" alt="Icon of Image Classifier" style="width: 200px; height: 200px;">
            <h2>Image Classifier</h2>
            <p>Image Classifier is a computer vision system that uses machine learning to accurately categorize images into different classes or categories by analyzing visual features and patterns.</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo11')">Learn More</button>
                <div id="additionalInfo11" class="additional-info">
                    <p>Image Classifier is a computer vision system that uses machine learning techniques to classify various objects and images. By analyzing visual features and patterns, the system can accurately categorize images into different classes or categories.</p>
                    <p>Platform: Multi-platform</p>
                    <p>Language: Python</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Computer-Vision/Image%20Classifier">GitHub</a></p>
                </div>
        </div>
        <div class="card">
            <img src="images/pv.png" alt="Icon of Project V" style="width: 200px; height: 200px;">
            <h2>Project V</h2>
            <p>Project V utilizes AI algorithms and data analysis to address environmental challenges and develop innovative solutions for the protection and preservation of the Earth.</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo12')">Learn More</button>
                <div id="additionalInfo12" class="additional-info">
                    <p>Project V is an initiative that harnesses the power of artificial intelligence for the protection and preservation of the Earth. Through advanced AI algorithms and data analysis, Project V aims to address environmental challenges, such as climate change, deforestation, and pollution. By leveraging AI technologies, Project V seeks to develop innovative solutions and strategies to safeguard the planet for future generations.</p>
                    <p>Platform: Multi-platform</p>
                    <p>Language: Python</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Natural%20Language%20Processing/Project%20V">GitHub</a></p>
                </div>
        </div>
        <div class="card">
            <img src="images/vidiad.png" alt="Icon of VIDIAD" style="width: 200px; height: 200px;">
            <h2>Vision-based Distance and Object Analysis(ViDiAD)</h2>
            <p>ViDiAD analyzes distances and objects in real-time using computer vision, aiding donkey cars in safe navigation and obstacle avoidance.</p>
            <p><i><b>ViDiAD will be launched in the first quarter of next year.</b></i></p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo13')">Learn More</button>
                <div id="additionalInfo13" class="additional-info">
                    <p>ViDiAD is an abbreviation for Vision-based Distance Analysis. It refers to the vision-based distance analysis component of a system used in a donkey car, which is an autonomous vehicle platform. The ViDiAD component helps the donkey car navigate its surroundings by estimating the distances to various obstacles or objects. It utilizes computer vision algorithms to calculate the depth information from the captured images, allowing the car to understand its position relative to nearby objects. This information is crucial for safe navigation and obstacle avoidance.</p>
                    <p><i><b>ViDiAD will be launched in the first quarter of next year.</b></i></p>
                    <p>Platform: Donkey Car</p>
                    <p>Language: Python</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/Computer-Vision/ViDiAD">GitHub</a></p>
                </div>
        </div>
        <div class="card">
            <img src="images/.png" alt="Icon of yujin_ive_lora" style="width: 200px; height: 200px;">
            <h2>yujin_ive_lora</h2>
            <p>yujin_ive_lora generates pictures of Yujin, an idol of the K-pop group IVE, using LoRA models, which are small Stable Diffusion models that modify standard checkpoint models.</p>
            <p><i><b>yujin_ive_lora V2 will be launched in the first quarter of next year.</b></i></p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo14')">Learn More</button>
                <div id="additionalInfo14" class="additional-info">
                    <p>yujin_ive_lora is a program designed to generate pictures of Yujin, who is an idol in the K-pop industry and a member of the South Korean girl group IVE. This program utilizes LoRA models, which are small Stable Diffusion models that apply subtle modifications to standard checkpoint models. LoRA models are known for their compact size, typically being 10 to 100 times smaller than traditional checkpoint models.</p>
                    <p><i><b>yujin_ive_lora V2 will be launched in the first quarter of next year.</b></i></p>
                    <p>Platform: Stable Diffusion</p>
                    <p>Language: /</p>
                    <p>Dataset (reg)Ôºö woman_v1-5_mse_vae_ddim50_cfg7_n4420</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Machine-Learning/tree/main/LoRA/yujin_ive_lora">GitHub</a></p>
                </div>
        </div>
    </section>
    <section class="card-container">
        <div class="card">
            <img src="images/pi.png" alt="Icon of œÄ" style="width: 200px; height: 200px;">
            <h2>œÄ</h2>
            <p>Calculate the value of œÄ using python</p>
            <button class="btn btn1" onclick="toggleAdditionalInfo('additionalInfo15')">Learn More</button>
                <div id="additionalInfo15" class="additional-info">
                    <p>œÄ is a mathematical constant that represents the ratio of the circumference of a circle to its diameter.</p>
                    <p>Platform: Multi-platform</p>
                    <p>Language: Python</p>
                    <p>Source model: Open-source -- <a href="https://github.com/Carson-We/Utility/tree/main/Tools/Mathematics/Pi">GitHub</a></p>
                </div>
        </div>
    </section>
    <footer>
        <p style="cursor: pointer;" onclick="goToCR()"><span class="cr"></span></p>
        <p style="cursor: pointer;" onclick="goToVE()"><span class="version"></span></p>
    </footer>
    <script src="scripts/word.js"></script>
    <iframe id="bottom-iframe" src="sitemap-b.html"></iframe>
</body>
</html>